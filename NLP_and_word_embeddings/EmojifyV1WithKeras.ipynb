{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the package we are going to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from emo_utils import *\n",
    "import emoji\n",
    "import random\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Dataset EMOJISET:\n",
    "\n",
    "We have a tiny dataset (X, Y) where:\n",
    "\n",
    " - X contains 127 sentences (strings)\n",
    " - Y contains a integer label between 0 and 4 corresponding to an emoji for each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = read_csv('data/train_emoji.csv')\n",
    "X_test, Y_test = read_csv('data/tesss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLen = len(max(X_train, key=len).split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "0 never talk to me again ðŸ˜ž\n",
      "1 I am proud of your achievements ðŸ˜„\n",
      "2 It is the worst day in my life ðŸ˜ž\n",
      "3 Miss you so much â¤ï¸\n",
      "4 food is life ðŸ´\n",
      "5 I love you mum â¤ï¸\n",
      "6 Stop saying bullshit ðŸ˜ž\n",
      "7 congratulations on your acceptance ðŸ˜„\n",
      "8 The assignment is too long  ðŸ˜ž\n",
      "9 I want to go play âš¾\n",
      "10 she did not answer my text  ðŸ˜ž\n",
      "11 Your stupidity has no limit ðŸ˜ž\n",
      "12 how many points did he score âš¾\n",
      "13 my algorithm performs poorly ðŸ˜ž\n",
      "14 I got approved ðŸ˜„\n",
      "15 Stop shouting at me ðŸ˜ž\n",
      "16 Sounds like a fun plan ha ha ðŸ˜„\n",
      "17 no one likes him ðŸ˜ž\n",
      "18 the game just finished âš¾\n",
      "19 I will celebrate soon ðŸ˜„\n",
      "20 So sad you are not coming ðŸ˜ž\n",
      "21 She is my dearest love â¤ï¸\n",
      "22 Good job ðŸ˜„\n",
      "23 It was funny lol ðŸ˜„\n",
      "24 candy is life  ðŸ˜„\n",
      "25 The chicago cubs won again âš¾\n",
      "26 I am hungry ðŸ´\n",
      "27 I am so excited to see you after so long ðŸ˜„\n",
      "28 you did well on you exam ðŸ˜„\n",
      "29 lets brunch some day ðŸ´\n",
      "30 he is so cute â¤ï¸\n",
      "31 How dare you ask that ðŸ˜ž\n",
      "32 do you want to join me for dinner  ðŸ´\n",
      "33 I said yes ðŸ˜„\n",
      "34 she is attractive â¤ï¸\n",
      "35 you suck ðŸ˜ž\n",
      "36 she smiles a lot ðŸ˜„\n",
      "37 he is laughing ðŸ˜„\n",
      "38 she takes forever to get ready  ðŸ˜ž\n",
      "39 French macaroon is so tasty ðŸ´\n",
      "40 we made it ðŸ˜„\n",
      "41 I am excited ðŸ˜„\n",
      "42 I adore my dogs â¤ï¸\n",
      "43 Congratulations ðŸ˜„\n",
      "44 this girl was mean ðŸ˜ž\n",
      "45 you two are cute â¤ï¸\n",
      "46 my code is working but the grader gave me zero ðŸ˜ž\n",
      "47 this joke is killing me haha ðŸ˜„\n",
      "48 do you like pizza  ðŸ´\n",
      "49 you got a down grade ðŸ˜ž\n",
      "50 I missed you â¤ï¸\n",
      "51 I think I will end up alone ðŸ˜ž\n",
      "52 I got humiliated by my sister ðŸ˜ž\n",
      "53 you are awful ðŸ˜ž\n",
      "54 I cooked meat ðŸ´\n",
      "55 This is so funny ðŸ˜„\n",
      "56 lets exercise âš¾\n",
      "57 he is the best player âš¾\n",
      "58 I am going to the stadium âš¾\n",
      "59 You are incredibly intelligent and talented ðŸ˜„\n",
      "60 Stop shouting at me ðŸ˜ž\n",
      "61 Who is your favorite player âš¾\n",
      "62 I like you a lot â¤ï¸\n",
      "63 i miss him â¤ï¸\n",
      "64 my dog just had a few puppies â¤ï¸\n",
      "65 I hate him ðŸ˜ž\n",
      "66 I want chinese food ðŸ´\n",
      "67 cookies are good ðŸ´\n",
      "68 her smile is so charming ðŸ˜„\n",
      "69 Bravo for the announcement it got a lot of traction ðŸ˜„\n",
      "70 she plays baseball âš¾\n",
      "71 he did an amazing job ðŸ˜„\n",
      "72 The baby is adorable â¤ï¸\n",
      "73 I was waiting for her for two hours  ðŸ˜ž\n",
      "74 funny ðŸ˜„\n",
      "75 I like it when people smile ðŸ˜„\n",
      "76 I love dogs â¤ï¸\n",
      "77 they are so kind and friendly â¤ï¸\n",
      "78 So bad that you cannot come with us ðŸ˜ž\n",
      "79 he likes baseball âš¾\n",
      "80 I am so impressed by your dedication to this project ðŸ˜„\n",
      "81 I am at the baseball game âš¾\n",
      "82 Bravo ðŸ˜„\n",
      "83 What a fun moment ðŸ˜„\n",
      "84 I want to have sushi for dinner ðŸ´\n",
      "85 I am very disappointed ðŸ˜ž\n",
      "86 he can not do anything ðŸ˜ž\n",
      "87 lol ðŸ˜„\n",
      "88 Lets have food together ðŸ´\n",
      "89 she is so cute â¤ï¸\n",
      "90 miss you my dear â¤ï¸\n",
      "91 I am looking for a date â¤ï¸\n",
      "92 I am frustrated ðŸ˜ž\n",
      "93 I lost my wallet ðŸ˜ž\n",
      "94 you failed the midterm ðŸ˜ž\n",
      "95 ha ha ha it was so funny ðŸ˜„\n",
      "96 Do you want to give me a hug â¤ï¸\n",
      "97 who is playing in the final âš¾\n",
      "98 she is happy ðŸ˜„\n",
      "99 You are not qualified for this position ðŸ˜ž\n",
      "100 I love my dad â¤ï¸\n",
      "101 this guy was such a joke ðŸ˜„\n",
      "102 Good joke ðŸ˜„\n",
      "103 This specialization is great ðŸ˜„\n",
      "104 you could not solve it ðŸ˜ž\n",
      "105 I am so happy for you ðŸ˜„\n",
      "106 Congrats on the new job ðŸ˜„\n",
      "107 I am proud of you forever ðŸ˜„\n",
      "108 I want to eat ðŸ´\n",
      "109 That catcher sucks  âš¾\n",
      "110 The first base man got the ball âš¾\n",
      "111 this is bad ðŸ˜ž\n",
      "112 you did not do your homework ðŸ˜ž\n",
      "113 I will have a cheese cake ðŸ´\n",
      "114 do you have a ball âš¾\n",
      "115 the lectures are great though  ðŸ˜„\n",
      "116 Are you down for baseball this afternoon âš¾\n",
      "117 what are the rules of the game âš¾\n",
      "118 I am always working ðŸ˜ž\n",
      "119 where is the stadium âš¾\n",
      "120 She is the cutest person I have ever seen â¤ï¸\n",
      "121 vegetables are healthy ðŸ´\n",
      "122 he is handsome â¤ï¸\n",
      "123 too bad that you were not here ðŸ˜ž\n",
      "124 you are a loser ðŸ˜ž\n",
      "125 I love indian food ðŸ´\n",
      "126 Who is down for a restaurant ðŸ´\n",
      "127 he had to make a home run âš¾\n",
      "128 I am ordering food ðŸ´\n",
      "129 What is wrong with you ðŸ˜ž\n",
      "130 I love you â¤ï¸\n",
      "131 great job ðŸ˜„\n",
      "Test:\n",
      "0 I want to eat\t ðŸ´\n",
      "1 he did not answer\t ðŸ˜ž\n",
      "2 he got a very nice raise\t ðŸ˜„\n",
      "3 she got me a nice present\t ðŸ˜„\n",
      "4 ha ha ha it was so funny\t ðŸ˜„\n",
      "5 he is a good friend\t ðŸ˜„\n",
      "6 I am upset\t ðŸ˜ž\n",
      "7 We had such a lovely dinner tonight\t ðŸ˜„\n",
      "8 where is the food\t ðŸ´\n",
      "9 Stop making this joke ha ha ha\t ðŸ˜„\n",
      "10 where is the ball\t âš¾\n",
      "11 work is hard\t ðŸ˜ž\n",
      "12 This girl is messing with me\t ðŸ˜ž\n",
      "13 are you serious ðŸ˜ž\n",
      "14 Let us go play baseball\t âš¾\n",
      "15 This stupid grader is not working \t ðŸ˜ž\n",
      "16 work is horrible\t ðŸ˜ž\n",
      "17 Congratulation for having a baby\t ðŸ˜„\n",
      "18 stop pissing me off ðŸ˜ž\n",
      "19 any suggestions for dinner\t ðŸ´\n",
      "20 I love taking breaks\t â¤ï¸\n",
      "21 you brighten my day\t ðŸ˜„\n",
      "22 I boiled rice\t ðŸ´\n",
      "23 she is a bully\t ðŸ˜ž\n",
      "24 Why are you feeling bad\t ðŸ˜ž\n",
      "25 I am upset\t ðŸ˜ž\n",
      "26 give me the ball âš¾\n",
      "27 My grandmother is the love of my life\t â¤ï¸\n",
      "28 enjoy your game âš¾\n",
      "29 valentine day is near\t ðŸ˜„\n",
      "30 I miss you so much\t â¤ï¸\n",
      "31 throw the ball\t âš¾\n",
      "32 My life is so boring\t ðŸ˜ž\n",
      "33 she said yes\t ðŸ˜„\n",
      "34 will you be my valentine\t ðŸ˜„\n",
      "35 he can pitch really well\t âš¾\n",
      "36 dance with me\t ðŸ˜„\n",
      "37 I am hungry ðŸ´\n",
      "38 See you at the restaurant\t ðŸ´\n",
      "39 I like to laugh\t ðŸ˜„\n",
      "40 I will  run âš¾\n",
      "41 I like your jacket \t â¤ï¸\n",
      "42 i miss her\t â¤ï¸\n",
      "43 what is your favorite baseball game\t âš¾\n",
      "44 Good job\t ðŸ˜„\n",
      "45 I love you to the stars and back\t â¤ï¸\n",
      "46 What you did was awesome\t ðŸ˜„\n",
      "47 ha ha ha lol\t ðŸ˜„\n",
      "48 I do not want to joke\t ðŸ˜ž\n",
      "49 go away\t ðŸ˜ž\n",
      "50 yesterday we lost again\t ðŸ˜ž\n",
      "51 family is all I have\t â¤ï¸\n",
      "52 you are failing this exercise\t ðŸ˜ž\n",
      "53 Good joke\t ðŸ˜„\n",
      "54 You deserve this nice prize\t ðŸ˜„\n",
      "55 I did not have breakfast  ðŸ´\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\")\n",
    "for index in range(len(Y_train)):\n",
    "    print(index, X_train[index], label_to_emoji(Y_train[index]))\n",
    "print(\"Test:\")\n",
    "for index in range(len(Y_test)):\n",
    "    print(index, X_test[index], label_to_emoji(Y_test[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2  Overview of the Emojifier-V1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting  ð‘Œ  from its current shape current shape (ð‘š,1) into a \"one-hot representation\" (ð‘š,5):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_oh_train = convert_to_one_hot(Y_train, C = 5)\n",
    "Y_oh_test = convert_to_one_hot(Y_test, C = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test `convert_to_one_hot` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert_to_one_hot:\n",
      "0 never talk to me again ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "1 I am proud of your achievements ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "2 It is the worst day in my life ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "3 Miss you so much â¤ï¸ [1. 0. 0. 0. 0.]\n",
      "4 food is life ðŸ´ [0. 0. 0. 0. 1.]\n",
      "5 I love you mum â¤ï¸ [1. 0. 0. 0. 0.]\n",
      "6 Stop saying bullshit ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "7 congratulations on your acceptance ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "8 The assignment is too long  ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "9 I want to go play âš¾ [0. 1. 0. 0. 0.]\n",
      "10 she did not answer my text  ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "11 Your stupidity has no limit ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "12 how many points did he score âš¾ [0. 1. 0. 0. 0.]\n",
      "13 my algorithm performs poorly ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "14 I got approved ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "15 Stop shouting at me ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "16 Sounds like a fun plan ha ha ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "17 no one likes him ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "18 the game just finished âš¾ [0. 1. 0. 0. 0.]\n",
      "19 I will celebrate soon ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "20 So sad you are not coming ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "21 She is my dearest love â¤ï¸ [1. 0. 0. 0. 0.]\n",
      "22 Good job ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "23 It was funny lol ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "24 candy is life  ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "25 The chicago cubs won again âš¾ [0. 1. 0. 0. 0.]\n",
      "26 I am hungry ðŸ´ [0. 0. 0. 0. 1.]\n",
      "27 I am so excited to see you after so long ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "28 you did well on you exam ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "29 lets brunch some day ðŸ´ [0. 0. 0. 0. 1.]\n",
      "30 he is so cute â¤ï¸ [1. 0. 0. 0. 0.]\n",
      "31 How dare you ask that ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "32 do you want to join me for dinner  ðŸ´ [0. 0. 0. 0. 1.]\n",
      "33 I said yes ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "34 she is attractive â¤ï¸ [1. 0. 0. 0. 0.]\n",
      "35 you suck ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "36 she smiles a lot ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "37 he is laughing ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "38 she takes forever to get ready  ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "39 French macaroon is so tasty ðŸ´ [0. 0. 0. 0. 1.]\n",
      "40 we made it ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "41 I am excited ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "42 I adore my dogs â¤ï¸ [1. 0. 0. 0. 0.]\n",
      "43 Congratulations ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "44 this girl was mean ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "45 you two are cute â¤ï¸ [1. 0. 0. 0. 0.]\n",
      "46 my code is working but the grader gave me zero ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "47 this joke is killing me haha ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "48 do you like pizza  ðŸ´ [0. 0. 0. 0. 1.]\n",
      "49 you got a down grade ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "50 I missed you â¤ï¸ [1. 0. 0. 0. 0.]\n",
      "51 I think I will end up alone ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "52 I got humiliated by my sister ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "53 you are awful ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "54 I cooked meat ðŸ´ [0. 0. 0. 0. 1.]\n",
      "55 This is so funny ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "56 lets exercise âš¾ [0. 1. 0. 0. 0.]\n",
      "57 he is the best player âš¾ [0. 1. 0. 0. 0.]\n",
      "58 I am going to the stadium âš¾ [0. 1. 0. 0. 0.]\n",
      "59 You are incredibly intelligent and talented ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "60 Stop shouting at me ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "61 Who is your favorite player âš¾ [0. 1. 0. 0. 0.]\n",
      "62 I like you a lot â¤ï¸ [1. 0. 0. 0. 0.]\n",
      "63 i miss him â¤ï¸ [1. 0. 0. 0. 0.]\n",
      "64 my dog just had a few puppies â¤ï¸ [1. 0. 0. 0. 0.]\n",
      "65 I hate him ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "66 I want chinese food ðŸ´ [0. 0. 0. 0. 1.]\n",
      "67 cookies are good ðŸ´ [0. 0. 0. 0. 1.]\n",
      "68 her smile is so charming ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "69 Bravo for the announcement it got a lot of traction ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "70 she plays baseball âš¾ [0. 1. 0. 0. 0.]\n",
      "71 he did an amazing job ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "72 The baby is adorable â¤ï¸ [1. 0. 0. 0. 0.]\n",
      "73 I was waiting for her for two hours  ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "74 funny ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "75 I like it when people smile ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "76 I love dogs â¤ï¸ [1. 0. 0. 0. 0.]\n",
      "77 they are so kind and friendly â¤ï¸ [1. 0. 0. 0. 0.]\n",
      "78 So bad that you cannot come with us ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "79 he likes baseball âš¾ [0. 1. 0. 0. 0.]\n",
      "80 I am so impressed by your dedication to this project ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "81 I am at the baseball game âš¾ [0. 1. 0. 0. 0.]\n",
      "82 Bravo ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "83 What a fun moment ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "84 I want to have sushi for dinner ðŸ´ [0. 0. 0. 0. 1.]\n",
      "85 I am very disappointed ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "86 he can not do anything ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "87 lol ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "88 Lets have food together ðŸ´ [0. 0. 0. 0. 1.]\n",
      "89 she is so cute â¤ï¸ [1. 0. 0. 0. 0.]\n",
      "90 miss you my dear â¤ï¸ [1. 0. 0. 0. 0.]\n",
      "91 I am looking for a date â¤ï¸ [1. 0. 0. 0. 0.]\n",
      "92 I am frustrated ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "93 I lost my wallet ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "94 you failed the midterm ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "95 ha ha ha it was so funny ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "96 Do you want to give me a hug â¤ï¸ [1. 0. 0. 0. 0.]\n",
      "97 who is playing in the final âš¾ [0. 1. 0. 0. 0.]\n",
      "98 she is happy ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "99 You are not qualified for this position ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "100 I love my dad â¤ï¸ [1. 0. 0. 0. 0.]\n",
      "101 this guy was such a joke ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "102 Good joke ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "103 This specialization is great ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "104 you could not solve it ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "105 I am so happy for you ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "106 Congrats on the new job ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "107 I am proud of you forever ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "108 I want to eat ðŸ´ [0. 0. 0. 0. 1.]\n",
      "109 That catcher sucks  âš¾ [0. 1. 0. 0. 0.]\n",
      "110 The first base man got the ball âš¾ [0. 1. 0. 0. 0.]\n",
      "111 this is bad ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "112 you did not do your homework ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "113 I will have a cheese cake ðŸ´ [0. 0. 0. 0. 1.]\n",
      "114 do you have a ball âš¾ [0. 1. 0. 0. 0.]\n",
      "115 the lectures are great though  ðŸ˜„ [0. 0. 1. 0. 0.]\n",
      "116 Are you down for baseball this afternoon âš¾ [0. 1. 0. 0. 0.]\n",
      "117 what are the rules of the game âš¾ [0. 1. 0. 0. 0.]\n",
      "118 I am always working ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "119 where is the stadium âš¾ [0. 1. 0. 0. 0.]\n",
      "120 She is the cutest person I have ever seen â¤ï¸ [1. 0. 0. 0. 0.]\n",
      "121 vegetables are healthy ðŸ´ [0. 0. 0. 0. 1.]\n",
      "122 he is handsome â¤ï¸ [1. 0. 0. 0. 0.]\n",
      "123 too bad that you were not here ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "124 you are a loser ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "125 I love indian food ðŸ´ [0. 0. 0. 0. 1.]\n",
      "126 Who is down for a restaurant ðŸ´ [0. 0. 0. 0. 1.]\n",
      "127 he had to make a home run âš¾ [0. 1. 0. 0. 0.]\n",
      "128 I am ordering food ðŸ´ [0. 0. 0. 0. 1.]\n",
      "129 What is wrong with you ðŸ˜ž [0. 0. 0. 1. 0.]\n",
      "130 I love you â¤ï¸ [1. 0. 0. 0. 0.]\n",
      "131 great job ðŸ˜„ [0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"convert_to_one_hot:\")\n",
    "for index in range(len(Y_train)):\n",
    "    print(index, X_train[index], label_to_emoji(Y_train[index]), Y_oh_train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Implementing Emojifier-V1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertind an input sentence into the word 50-dimensional GloVe vector representation:\n",
    "\n",
    "We are loaded:\n",
    "\n",
    "- `word_to_index`: dictionary mapping from words to their indices in the vocabulary (400,001 words, with the valid indices ranging from 0 to 400,000)\n",
    "- `index_to_word`: dictionary mapping from indices to their corresponding words in the vocabulary\n",
    "- `word_to_vec_map`: dictionary mapping words to their GloVe vector representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('data/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text GloVo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Index: 185457 \n",
      "Word: i \n",
      "Vector: [ 1.1891e-01  1.5255e-01 -8.2073e-02 -7.4144e-01  7.5917e-01 -4.8328e-01\n",
      " -3.1009e-01  5.1476e-01 -9.8708e-01  6.1757e-04 -1.5043e-01  8.3770e-01\n",
      " -1.0797e+00 -5.1460e-01  1.3188e+00  6.2007e-01  1.3779e-01  4.7108e-01\n",
      " -7.2874e-02 -7.2675e-01 -7.4116e-01  7.5263e-01  8.8180e-01  2.9561e-01\n",
      "  1.3548e+00 -2.5701e+00 -1.3523e+00  4.5880e-01  1.0068e+00 -1.1856e+00\n",
      "  3.4737e+00  7.7898e-01 -7.2929e-01  2.5102e-01 -2.6156e-01 -3.4684e-01\n",
      "  5.5841e-01  7.5098e-01  4.9830e-01 -2.6823e-01 -2.7443e-03 -1.8298e-02\n",
      " -2.8096e-01  5.5318e-01  3.7706e-02  1.8555e-01 -1.5025e-01 -5.7512e-01\n",
      " -2.6671e-01  9.2121e-01]\n",
      "\n",
      "Index: 52943 \n",
      "Word: am \n",
      "Vector: [ 0.34664   0.39805   0.4897   -0.51421   0.54574  -1.2005    0.32107\n",
      "  0.74004  -1.4979   -0.19651  -0.12631  -0.37703  -0.62569   0.038792\n",
      "  1.0579    0.77199  -0.18589   1.3032   -0.72128   0.40231   0.066442\n",
      "  1.2315    0.93956   1.3903    1.5334   -1.473    -0.34997   0.31562\n",
      "  0.90691   0.45498   2.5481    0.1641   -0.607     0.27061  -0.79072\n",
      " -1.146     0.91795  -0.11797   0.23526  -0.12659   0.66527  -0.91816\n",
      "  0.10048   0.70457  -0.21777   0.52479  -0.54452   0.086576  0.34037\n",
      "  1.3588  ]\n",
      "\n",
      "Index: 52879 \n",
      "Word: always \n",
      "Vector: [ 1.5778e-01  2.6380e-01 -4.4502e-01 -4.6819e-01  8.8558e-01 -1.1134e-01\n",
      " -2.2886e-01  2.5545e-01 -5.3813e-01  3.3681e-01  2.2259e-02  6.7810e-01\n",
      " -4.8255e-01  2.4954e-03  5.5938e-01  4.1020e-01  6.1032e-01  1.8802e-01\n",
      "  2.2943e-01 -9.8910e-01 -7.2062e-01  5.2451e-01  3.3157e-01  4.8512e-01\n",
      "  9.6760e-01 -1.9021e+00 -9.3215e-01  4.7344e-01  8.5667e-01 -5.2803e-01\n",
      "  3.1994e+00  5.1182e-01 -8.3763e-02 -4.8335e-01 -1.2347e-01 -2.7206e-01\n",
      " -1.4103e-01  5.9470e-01 -6.1738e-01 -2.9798e-01 -1.6374e-01  8.6967e-03\n",
      " -1.2262e-01  6.6676e-01  9.7146e-02 -4.4463e-02 -2.7159e-01 -1.4953e-01\n",
      " -2.2232e-01  5.2731e-01]\n",
      "\n",
      "Index: 389883 \n",
      "Word: working \n",
      "Vector: [ 0.25792   -0.14413   -0.035634  -0.60551    0.11004   -0.058799\n",
      " -1.2209    -0.031605  -0.023699  -0.37419    0.28924    0.12331\n",
      " -0.31903    0.65017    0.28362   -0.20956    0.30423    0.75571\n",
      "  0.47964   -0.41976    0.68923    0.92026    0.070798   0.3948\n",
      "  0.24721   -1.4038    -0.14209   -0.6946    -0.035052   0.0041205\n",
      "  3.4024     0.036271  -0.58483   -0.72107    0.036996   0.33065\n",
      " -0.27332    0.51897    0.3499     0.061199  -0.36178   -0.26534\n",
      "  0.4271     0.0081181  0.19844   -0.38564   -0.35535    0.032932\n",
      " -0.50055    0.54358  ]\n"
     ]
    }
   ],
   "source": [
    "#I am always working\n",
    "print(\"\\nIndex:\", word_to_index[\"i\"], \"\\nWord:\", \"i\", \"\\nVector:\", word_to_vec_map[\"i\"])\n",
    "print(\"\\nIndex:\", word_to_index[\"am\"], \"\\nWord:\", \"am\", \"\\nVector:\", word_to_vec_map[\"am\"])\n",
    "print(\"\\nIndex:\", word_to_index[\"always\"], \"\\nWord:\", \"always\", \"\\nVector:\", word_to_vec_map[\"always\"])\n",
    "print(\"\\nIndex:\", word_to_index[\"working\"], \"\\nWord:\", \"working\", \"\\nVector:\", word_to_vec_map[\"working\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sentence_to_avg()` method convert every sentence to lower-case, then split the sentence into a list of words. For each word in the sentence, access its GloVe representation. Then, average all these values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sentence_to_avg(sentence, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    Converts a sentence (string) into a list of words (strings). Extracts the GloVe representation of each word\n",
    "    and averages its value into a single vector encoding the meaning of the sentence.\n",
    "    \n",
    "    Arguments:\n",
    "    sentence -- string, one training example from X\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    \n",
    "    Returns:\n",
    "    avg -- average vector encoding information about the sentence, numpy-array of shape (50,)\n",
    "    \"\"\"\n",
    "    \n",
    "    words = None\n",
    "    words = sentence.lower()\n",
    "    words = words.split()\n",
    "\n",
    "    avg = list()\n",
    "    for i in range(0, len(word_to_vec_map[words[0]])):\n",
    "        avg.append(0)\n",
    "    \n",
    "    for i in range(0,len(words)):\n",
    "        avg = avg + word_to_vec_map[words[i]]\n",
    "    avg = avg/len(words)\n",
    "        \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test `sentence_to_avg()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg =  [ 0.2203125   0.1675675  -0.01825675 -0.5823375   0.5751325  -0.46347975\n",
      " -0.359695    0.36966125 -0.76170225 -0.05831811  0.00868975  0.31552\n",
      " -0.6267425   0.04421435  0.804925    0.398175    0.2166125   0.6795025\n",
      " -0.021271   -0.433325   -0.176527    0.857225    0.555932    0.6414575\n",
      "  1.0257525  -1.83725    -0.6941275   0.138315    0.683832   -0.31363238\n",
      "  3.1559      0.37279275 -0.50122075 -0.1706975  -0.2846885  -0.3585625\n",
      "  0.2655025   0.43667     0.11652    -0.15790025  0.03425143 -0.29827532\n",
      "  0.031       0.48315703  0.0288805   0.07005925 -0.3304275  -0.1512855\n",
      " -0.1623025   0.837725  ]\n"
     ]
    }
   ],
   "source": [
    "avg = sentence_to_avg(\"I am always working\", word_to_vec_map)\n",
    "print(\"avg = \", avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Emojifier-V1` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "132/132 [==============================] - 3s 23ms/step - loss: 0.7403 - acc: 0.5030\n",
      "Epoch 2/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.6802 - acc: 0.6076\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.6315 - acc: 0.6682\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.5939 - acc: 0.7076\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.5645 - acc: 0.7348\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.5424 - acc: 0.7591\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 0s 697us/step - loss: 0.5249 - acc: 0.7742\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.5114 - acc: 0.7803\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.5007 - acc: 0.7924\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4914 - acc: 0.7955\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4839 - acc: 0.7970\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4775 - acc: 0.7939\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4719 - acc: 0.7939\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4671 - acc: 0.7955\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4624 - acc: 0.7970\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4583 - acc: 0.7970\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4545 - acc: 0.7985\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4513 - acc: 0.8000\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4474 - acc: 0.7985\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 0s 803us/step - loss: 0.4443 - acc: 0.8000\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4410 - acc: 0.8015\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4378 - acc: 0.8015\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4348 - acc: 0.8015\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4323 - acc: 0.8015\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4291 - acc: 0.8030\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4264 - acc: 0.8030\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4235 - acc: 0.8030\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4208 - acc: 0.8045\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 0s 652us/step - loss: 0.4179 - acc: 0.8076\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4152 - acc: 0.8061\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4126 - acc: 0.8045\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4100 - acc: 0.8106\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4075 - acc: 0.8106\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4052 - acc: 0.8121\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4028 - acc: 0.8091A: 0s - loss: 0.3972 - acc: 0.815\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4002 - acc: 0.8091\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3978 - acc: 0.8091\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.3990 - acc: 0.806 - 0s 1ms/step - loss: 0.3956 - acc: 0.8091\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3934 - acc: 0.8091\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3915 - acc: 0.8121\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3890 - acc: 0.8121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.115000). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3870 - acc: 0.8121\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3847 - acc: 0.8136\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3826 - acc: 0.8167\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3806 - acc: 0.8167\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3785 - acc: 0.8182\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3765 - acc: 0.8182\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3745 - acc: 0.8197\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3726 - acc: 0.8212\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 0s 614us/step - loss: 0.3706 - acc: 0.8227\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3687 - acc: 0.8242\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3669 - acc: 0.8242\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.3678 - acc: 0.829 - 0s 1ms/step - loss: 0.3652 - acc: 0.8288\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3636 - acc: 0.8288\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3618 - acc: 0.8318\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3601 - acc: 0.8333\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3584 - acc: 0.8333\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3568 - acc: 0.8333\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3550 - acc: 0.8364\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3536 - acc: 0.8364\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3520 - acc: 0.8379\n",
      "Epoch 62/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3501 - acc: 0.8379\n",
      "Epoch 63/100\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.3442 - acc: 0.832 - 0s 659us/step - loss: 0.3486 - acc: 0.8379\n",
      "Epoch 64/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3476 - acc: 0.8379\n",
      "Epoch 65/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3457 - acc: 0.8394\n",
      "Epoch 66/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3442 - acc: 0.8394\n",
      "Epoch 67/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3428 - acc: 0.8424\n",
      "Epoch 68/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3417 - acc: 0.8439\n",
      "Epoch 69/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3402 - acc: 0.8439\n",
      "Epoch 70/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3387 - acc: 0.8439\n",
      "Epoch 71/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3374 - acc: 0.8470\n",
      "Epoch 72/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3361 - acc: 0.8470\n",
      "Epoch 73/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3346 - acc: 0.8485\n",
      "Epoch 74/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3333 - acc: 0.8485\n",
      "Epoch 75/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3320 - acc: 0.8500\n",
      "Epoch 76/100\n",
      "132/132 [==============================] - 0s 917us/step - loss: 0.3308 - acc: 0.8515\n",
      "Epoch 77/100\n",
      "132/132 [==============================] - 0s 720us/step - loss: 0.3294 - acc: 0.8530\n",
      "Epoch 78/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3282 - acc: 0.8530\n",
      "Epoch 79/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3269 - acc: 0.8530\n",
      "Epoch 80/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3255 - acc: 0.8545\n",
      "Epoch 81/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3245 - acc: 0.8576\n",
      "Epoch 82/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3232 - acc: 0.8591\n",
      "Epoch 83/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3219 - acc: 0.8606\n",
      "Epoch 84/100\n",
      "132/132 [==============================] - 0s 962us/step - loss: 0.3208 - acc: 0.8591\n",
      "Epoch 85/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3197 - acc: 0.8621\n",
      "Epoch 86/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3187 - acc: 0.8652\n",
      "Epoch 87/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3175 - acc: 0.8652\n",
      "Epoch 88/100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.103000). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "132/132 [==============================] - 0s 682us/step - loss: 0.3163 - acc: 0.8667\n",
      "Epoch 89/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3157 - acc: 0.8636\n",
      "Epoch 90/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3141 - acc: 0.8636\n",
      "Epoch 91/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3131 - acc: 0.8667\n",
      "Epoch 92/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3126 - acc: 0.8682\n",
      "Epoch 93/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3110 - acc: 0.8727\n",
      "Epoch 94/100\n",
      "132/132 [==============================] - 0s 674us/step - loss: 0.3100 - acc: 0.8682\n",
      "Epoch 95/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3094 - acc: 0.8682\n",
      "Epoch 96/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3079 - acc: 0.8712\n",
      "Epoch 97/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3069 - acc: 0.8727\n",
      "Epoch 98/100\n",
      "110/132 [========================>.....] - ETA: 0s - loss: 0.3109 - acc: 0.869"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.132000). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3061 - acc: 0.8758\n",
      "Epoch 99/100\n",
      "132/132 [==============================] - 0s 894us/step - loss: 0.3050 - acc: 0.8773\n",
      "Epoch 100/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3041 - acc: 0.8773\n",
      "132/132 [==============================] - 1s 6ms/step\n",
      "\n",
      "acc: 87.73%\n"
     ]
    }
   ],
   "source": [
    "# Input - Layer\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=50, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "X = np.zeros((len(X_train), 50), dtype=float)\n",
    "for i in range(0, len(X_train)):\n",
    "    X[i] = sentence_to_avg(X_train[i], word_to_vec_map)\n",
    "\n",
    "model.fit(X, Y_oh_train, epochs = 100, batch_size=10)\n",
    "\n",
    "scores = model.evaluate(X, Y_oh_train)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
