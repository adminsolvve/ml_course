{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the package we are going to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from emo_utils import *\n",
    "import emoji\n",
    "import random\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Dataset EMOJISET:\n",
    "\n",
    "We have a tiny dataset (X, Y) where:\n",
    "\n",
    " - X contains 127 sentences (strings)\n",
    " - Y contains a integer label between 0 and 4 corresponding to an emoji for each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = read_csv('data/train_emoji.csv')\n",
    "X_test, Y_test = read_csv('data/tesss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLen = len(max(X_train, key=len).split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "0 never talk to me again 😞\n",
      "1 I am proud of your achievements 😄\n",
      "2 It is the worst day in my life 😞\n",
      "3 Miss you so much ❤️\n",
      "4 food is life 🍴\n",
      "5 I love you mum ❤️\n",
      "6 Stop saying bullshit 😞\n",
      "7 congratulations on your acceptance 😄\n",
      "8 The assignment is too long  😞\n",
      "9 I want to go play ⚾\n",
      "10 she did not answer my text  😞\n",
      "11 Your stupidity has no limit 😞\n",
      "12 how many points did he score ⚾\n",
      "13 my algorithm performs poorly 😞\n",
      "14 I got approved 😄\n",
      "15 Stop shouting at me 😞\n",
      "16 Sounds like a fun plan ha ha 😄\n",
      "17 no one likes him 😞\n",
      "18 the game just finished ⚾\n",
      "19 I will celebrate soon 😄\n",
      "20 So sad you are not coming 😞\n",
      "21 She is my dearest love ❤️\n",
      "22 Good job 😄\n",
      "23 It was funny lol 😄\n",
      "24 candy is life  😄\n",
      "25 The chicago cubs won again ⚾\n",
      "26 I am hungry 🍴\n",
      "27 I am so excited to see you after so long 😄\n",
      "28 you did well on you exam 😄\n",
      "29 lets brunch some day 🍴\n",
      "30 he is so cute ❤️\n",
      "31 How dare you ask that 😞\n",
      "32 do you want to join me for dinner  🍴\n",
      "33 I said yes 😄\n",
      "34 she is attractive ❤️\n",
      "35 you suck 😞\n",
      "36 she smiles a lot 😄\n",
      "37 he is laughing 😄\n",
      "38 she takes forever to get ready  😞\n",
      "39 French macaroon is so tasty 🍴\n",
      "40 we made it 😄\n",
      "41 I am excited 😄\n",
      "42 I adore my dogs ❤️\n",
      "43 Congratulations 😄\n",
      "44 this girl was mean 😞\n",
      "45 you two are cute ❤️\n",
      "46 my code is working but the grader gave me zero 😞\n",
      "47 this joke is killing me haha 😄\n",
      "48 do you like pizza  🍴\n",
      "49 you got a down grade 😞\n",
      "50 I missed you ❤️\n",
      "51 I think I will end up alone 😞\n",
      "52 I got humiliated by my sister 😞\n",
      "53 you are awful 😞\n",
      "54 I cooked meat 🍴\n",
      "55 This is so funny 😄\n",
      "56 lets exercise ⚾\n",
      "57 he is the best player ⚾\n",
      "58 I am going to the stadium ⚾\n",
      "59 You are incredibly intelligent and talented 😄\n",
      "60 Stop shouting at me 😞\n",
      "61 Who is your favorite player ⚾\n",
      "62 I like you a lot ❤️\n",
      "63 i miss him ❤️\n",
      "64 my dog just had a few puppies ❤️\n",
      "65 I hate him 😞\n",
      "66 I want chinese food 🍴\n",
      "67 cookies are good 🍴\n",
      "68 her smile is so charming 😄\n",
      "69 Bravo for the announcement it got a lot of traction 😄\n",
      "70 she plays baseball ⚾\n",
      "71 he did an amazing job 😄\n",
      "72 The baby is adorable ❤️\n",
      "73 I was waiting for her for two hours  😞\n",
      "74 funny 😄\n",
      "75 I like it when people smile 😄\n",
      "76 I love dogs ❤️\n",
      "77 they are so kind and friendly ❤️\n",
      "78 So bad that you cannot come with us 😞\n",
      "79 he likes baseball ⚾\n",
      "80 I am so impressed by your dedication to this project 😄\n",
      "81 I am at the baseball game ⚾\n",
      "82 Bravo 😄\n",
      "83 What a fun moment 😄\n",
      "84 I want to have sushi for dinner 🍴\n",
      "85 I am very disappointed 😞\n",
      "86 he can not do anything 😞\n",
      "87 lol 😄\n",
      "88 Lets have food together 🍴\n",
      "89 she is so cute ❤️\n",
      "90 miss you my dear ❤️\n",
      "91 I am looking for a date ❤️\n",
      "92 I am frustrated 😞\n",
      "93 I lost my wallet 😞\n",
      "94 you failed the midterm 😞\n",
      "95 ha ha ha it was so funny 😄\n",
      "96 Do you want to give me a hug ❤️\n",
      "97 who is playing in the final ⚾\n",
      "98 she is happy 😄\n",
      "99 You are not qualified for this position 😞\n",
      "100 I love my dad ❤️\n",
      "101 this guy was such a joke 😄\n",
      "102 Good joke 😄\n",
      "103 This specialization is great 😄\n",
      "104 you could not solve it 😞\n",
      "105 I am so happy for you 😄\n",
      "106 Congrats on the new job 😄\n",
      "107 I am proud of you forever 😄\n",
      "108 I want to eat 🍴\n",
      "109 That catcher sucks  ⚾\n",
      "110 The first base man got the ball ⚾\n",
      "111 this is bad 😞\n",
      "112 you did not do your homework 😞\n",
      "113 I will have a cheese cake 🍴\n",
      "114 do you have a ball ⚾\n",
      "115 the lectures are great though  😄\n",
      "116 Are you down for baseball this afternoon ⚾\n",
      "117 what are the rules of the game ⚾\n",
      "118 I am always working 😞\n",
      "119 where is the stadium ⚾\n",
      "120 She is the cutest person I have ever seen ❤️\n",
      "121 vegetables are healthy 🍴\n",
      "122 he is handsome ❤️\n",
      "123 too bad that you were not here 😞\n",
      "124 you are a loser 😞\n",
      "125 I love indian food 🍴\n",
      "126 Who is down for a restaurant 🍴\n",
      "127 he had to make a home run ⚾\n",
      "128 I am ordering food 🍴\n",
      "129 What is wrong with you 😞\n",
      "130 I love you ❤️\n",
      "131 great job 😄\n",
      "Test:\n",
      "0 I want to eat\t 🍴\n",
      "1 he did not answer\t 😞\n",
      "2 he got a very nice raise\t 😄\n",
      "3 she got me a nice present\t 😄\n",
      "4 ha ha ha it was so funny\t 😄\n",
      "5 he is a good friend\t 😄\n",
      "6 I am upset\t 😞\n",
      "7 We had such a lovely dinner tonight\t 😄\n",
      "8 where is the food\t 🍴\n",
      "9 Stop making this joke ha ha ha\t 😄\n",
      "10 where is the ball\t ⚾\n",
      "11 work is hard\t 😞\n",
      "12 This girl is messing with me\t 😞\n",
      "13 are you serious 😞\n",
      "14 Let us go play baseball\t ⚾\n",
      "15 This stupid grader is not working \t 😞\n",
      "16 work is horrible\t 😞\n",
      "17 Congratulation for having a baby\t 😄\n",
      "18 stop pissing me off 😞\n",
      "19 any suggestions for dinner\t 🍴\n",
      "20 I love taking breaks\t ❤️\n",
      "21 you brighten my day\t 😄\n",
      "22 I boiled rice\t 🍴\n",
      "23 she is a bully\t 😞\n",
      "24 Why are you feeling bad\t 😞\n",
      "25 I am upset\t 😞\n",
      "26 give me the ball ⚾\n",
      "27 My grandmother is the love of my life\t ❤️\n",
      "28 enjoy your game ⚾\n",
      "29 valentine day is near\t 😄\n",
      "30 I miss you so much\t ❤️\n",
      "31 throw the ball\t ⚾\n",
      "32 My life is so boring\t 😞\n",
      "33 she said yes\t 😄\n",
      "34 will you be my valentine\t 😄\n",
      "35 he can pitch really well\t ⚾\n",
      "36 dance with me\t 😄\n",
      "37 I am hungry 🍴\n",
      "38 See you at the restaurant\t 🍴\n",
      "39 I like to laugh\t 😄\n",
      "40 I will  run ⚾\n",
      "41 I like your jacket \t ❤️\n",
      "42 i miss her\t ❤️\n",
      "43 what is your favorite baseball game\t ⚾\n",
      "44 Good job\t 😄\n",
      "45 I love you to the stars and back\t ❤️\n",
      "46 What you did was awesome\t 😄\n",
      "47 ha ha ha lol\t 😄\n",
      "48 I do not want to joke\t 😞\n",
      "49 go away\t 😞\n",
      "50 yesterday we lost again\t 😞\n",
      "51 family is all I have\t ❤️\n",
      "52 you are failing this exercise\t 😞\n",
      "53 Good joke\t 😄\n",
      "54 You deserve this nice prize\t 😄\n",
      "55 I did not have breakfast  🍴\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\")\n",
    "for index in range(len(Y_train)):\n",
    "    print(index, X_train[index], label_to_emoji(Y_train[index]))\n",
    "print(\"Test:\")\n",
    "for index in range(len(Y_test)):\n",
    "    print(index, X_test[index], label_to_emoji(Y_test[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2  Overview of the Emojifier-V1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting  𝑌  from its current shape current shape (𝑚,1) into a \"one-hot representation\" (𝑚,5):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_oh_train = convert_to_one_hot(Y_train, C = 5)\n",
    "Y_oh_test = convert_to_one_hot(Y_test, C = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test `convert_to_one_hot` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert_to_one_hot:\n",
      "0 never talk to me again 😞 [0. 0. 0. 1. 0.]\n",
      "1 I am proud of your achievements 😄 [0. 0. 1. 0. 0.]\n",
      "2 It is the worst day in my life 😞 [0. 0. 0. 1. 0.]\n",
      "3 Miss you so much ❤️ [1. 0. 0. 0. 0.]\n",
      "4 food is life 🍴 [0. 0. 0. 0. 1.]\n",
      "5 I love you mum ❤️ [1. 0. 0. 0. 0.]\n",
      "6 Stop saying bullshit 😞 [0. 0. 0. 1. 0.]\n",
      "7 congratulations on your acceptance 😄 [0. 0. 1. 0. 0.]\n",
      "8 The assignment is too long  😞 [0. 0. 0. 1. 0.]\n",
      "9 I want to go play ⚾ [0. 1. 0. 0. 0.]\n",
      "10 she did not answer my text  😞 [0. 0. 0. 1. 0.]\n",
      "11 Your stupidity has no limit 😞 [0. 0. 0. 1. 0.]\n",
      "12 how many points did he score ⚾ [0. 1. 0. 0. 0.]\n",
      "13 my algorithm performs poorly 😞 [0. 0. 0. 1. 0.]\n",
      "14 I got approved 😄 [0. 0. 1. 0. 0.]\n",
      "15 Stop shouting at me 😞 [0. 0. 0. 1. 0.]\n",
      "16 Sounds like a fun plan ha ha 😄 [0. 0. 1. 0. 0.]\n",
      "17 no one likes him 😞 [0. 0. 0. 1. 0.]\n",
      "18 the game just finished ⚾ [0. 1. 0. 0. 0.]\n",
      "19 I will celebrate soon 😄 [0. 0. 1. 0. 0.]\n",
      "20 So sad you are not coming 😞 [0. 0. 0. 1. 0.]\n",
      "21 She is my dearest love ❤️ [1. 0. 0. 0. 0.]\n",
      "22 Good job 😄 [0. 0. 1. 0. 0.]\n",
      "23 It was funny lol 😄 [0. 0. 1. 0. 0.]\n",
      "24 candy is life  😄 [0. 0. 1. 0. 0.]\n",
      "25 The chicago cubs won again ⚾ [0. 1. 0. 0. 0.]\n",
      "26 I am hungry 🍴 [0. 0. 0. 0. 1.]\n",
      "27 I am so excited to see you after so long 😄 [0. 0. 1. 0. 0.]\n",
      "28 you did well on you exam 😄 [0. 0. 1. 0. 0.]\n",
      "29 lets brunch some day 🍴 [0. 0. 0. 0. 1.]\n",
      "30 he is so cute ❤️ [1. 0. 0. 0. 0.]\n",
      "31 How dare you ask that 😞 [0. 0. 0. 1. 0.]\n",
      "32 do you want to join me for dinner  🍴 [0. 0. 0. 0. 1.]\n",
      "33 I said yes 😄 [0. 0. 1. 0. 0.]\n",
      "34 she is attractive ❤️ [1. 0. 0. 0. 0.]\n",
      "35 you suck 😞 [0. 0. 0. 1. 0.]\n",
      "36 she smiles a lot 😄 [0. 0. 1. 0. 0.]\n",
      "37 he is laughing 😄 [0. 0. 1. 0. 0.]\n",
      "38 she takes forever to get ready  😞 [0. 0. 0. 1. 0.]\n",
      "39 French macaroon is so tasty 🍴 [0. 0. 0. 0. 1.]\n",
      "40 we made it 😄 [0. 0. 1. 0. 0.]\n",
      "41 I am excited 😄 [0. 0. 1. 0. 0.]\n",
      "42 I adore my dogs ❤️ [1. 0. 0. 0. 0.]\n",
      "43 Congratulations 😄 [0. 0. 1. 0. 0.]\n",
      "44 this girl was mean 😞 [0. 0. 0. 1. 0.]\n",
      "45 you two are cute ❤️ [1. 0. 0. 0. 0.]\n",
      "46 my code is working but the grader gave me zero 😞 [0. 0. 0. 1. 0.]\n",
      "47 this joke is killing me haha 😄 [0. 0. 1. 0. 0.]\n",
      "48 do you like pizza  🍴 [0. 0. 0. 0. 1.]\n",
      "49 you got a down grade 😞 [0. 0. 0. 1. 0.]\n",
      "50 I missed you ❤️ [1. 0. 0. 0. 0.]\n",
      "51 I think I will end up alone 😞 [0. 0. 0. 1. 0.]\n",
      "52 I got humiliated by my sister 😞 [0. 0. 0. 1. 0.]\n",
      "53 you are awful 😞 [0. 0. 0. 1. 0.]\n",
      "54 I cooked meat 🍴 [0. 0. 0. 0. 1.]\n",
      "55 This is so funny 😄 [0. 0. 1. 0. 0.]\n",
      "56 lets exercise ⚾ [0. 1. 0. 0. 0.]\n",
      "57 he is the best player ⚾ [0. 1. 0. 0. 0.]\n",
      "58 I am going to the stadium ⚾ [0. 1. 0. 0. 0.]\n",
      "59 You are incredibly intelligent and talented 😄 [0. 0. 1. 0. 0.]\n",
      "60 Stop shouting at me 😞 [0. 0. 0. 1. 0.]\n",
      "61 Who is your favorite player ⚾ [0. 1. 0. 0. 0.]\n",
      "62 I like you a lot ❤️ [1. 0. 0. 0. 0.]\n",
      "63 i miss him ❤️ [1. 0. 0. 0. 0.]\n",
      "64 my dog just had a few puppies ❤️ [1. 0. 0. 0. 0.]\n",
      "65 I hate him 😞 [0. 0. 0. 1. 0.]\n",
      "66 I want chinese food 🍴 [0. 0. 0. 0. 1.]\n",
      "67 cookies are good 🍴 [0. 0. 0. 0. 1.]\n",
      "68 her smile is so charming 😄 [0. 0. 1. 0. 0.]\n",
      "69 Bravo for the announcement it got a lot of traction 😄 [0. 0. 1. 0. 0.]\n",
      "70 she plays baseball ⚾ [0. 1. 0. 0. 0.]\n",
      "71 he did an amazing job 😄 [0. 0. 1. 0. 0.]\n",
      "72 The baby is adorable ❤️ [1. 0. 0. 0. 0.]\n",
      "73 I was waiting for her for two hours  😞 [0. 0. 0. 1. 0.]\n",
      "74 funny 😄 [0. 0. 1. 0. 0.]\n",
      "75 I like it when people smile 😄 [0. 0. 1. 0. 0.]\n",
      "76 I love dogs ❤️ [1. 0. 0. 0. 0.]\n",
      "77 they are so kind and friendly ❤️ [1. 0. 0. 0. 0.]\n",
      "78 So bad that you cannot come with us 😞 [0. 0. 0. 1. 0.]\n",
      "79 he likes baseball ⚾ [0. 1. 0. 0. 0.]\n",
      "80 I am so impressed by your dedication to this project 😄 [0. 0. 1. 0. 0.]\n",
      "81 I am at the baseball game ⚾ [0. 1. 0. 0. 0.]\n",
      "82 Bravo 😄 [0. 0. 1. 0. 0.]\n",
      "83 What a fun moment 😄 [0. 0. 1. 0. 0.]\n",
      "84 I want to have sushi for dinner 🍴 [0. 0. 0. 0. 1.]\n",
      "85 I am very disappointed 😞 [0. 0. 0. 1. 0.]\n",
      "86 he can not do anything 😞 [0. 0. 0. 1. 0.]\n",
      "87 lol 😄 [0. 0. 1. 0. 0.]\n",
      "88 Lets have food together 🍴 [0. 0. 0. 0. 1.]\n",
      "89 she is so cute ❤️ [1. 0. 0. 0. 0.]\n",
      "90 miss you my dear ❤️ [1. 0. 0. 0. 0.]\n",
      "91 I am looking for a date ❤️ [1. 0. 0. 0. 0.]\n",
      "92 I am frustrated 😞 [0. 0. 0. 1. 0.]\n",
      "93 I lost my wallet 😞 [0. 0. 0. 1. 0.]\n",
      "94 you failed the midterm 😞 [0. 0. 0. 1. 0.]\n",
      "95 ha ha ha it was so funny 😄 [0. 0. 1. 0. 0.]\n",
      "96 Do you want to give me a hug ❤️ [1. 0. 0. 0. 0.]\n",
      "97 who is playing in the final ⚾ [0. 1. 0. 0. 0.]\n",
      "98 she is happy 😄 [0. 0. 1. 0. 0.]\n",
      "99 You are not qualified for this position 😞 [0. 0. 0. 1. 0.]\n",
      "100 I love my dad ❤️ [1. 0. 0. 0. 0.]\n",
      "101 this guy was such a joke 😄 [0. 0. 1. 0. 0.]\n",
      "102 Good joke 😄 [0. 0. 1. 0. 0.]\n",
      "103 This specialization is great 😄 [0. 0. 1. 0. 0.]\n",
      "104 you could not solve it 😞 [0. 0. 0. 1. 0.]\n",
      "105 I am so happy for you 😄 [0. 0. 1. 0. 0.]\n",
      "106 Congrats on the new job 😄 [0. 0. 1. 0. 0.]\n",
      "107 I am proud of you forever 😄 [0. 0. 1. 0. 0.]\n",
      "108 I want to eat 🍴 [0. 0. 0. 0. 1.]\n",
      "109 That catcher sucks  ⚾ [0. 1. 0. 0. 0.]\n",
      "110 The first base man got the ball ⚾ [0. 1. 0. 0. 0.]\n",
      "111 this is bad 😞 [0. 0. 0. 1. 0.]\n",
      "112 you did not do your homework 😞 [0. 0. 0. 1. 0.]\n",
      "113 I will have a cheese cake 🍴 [0. 0. 0. 0. 1.]\n",
      "114 do you have a ball ⚾ [0. 1. 0. 0. 0.]\n",
      "115 the lectures are great though  😄 [0. 0. 1. 0. 0.]\n",
      "116 Are you down for baseball this afternoon ⚾ [0. 1. 0. 0. 0.]\n",
      "117 what are the rules of the game ⚾ [0. 1. 0. 0. 0.]\n",
      "118 I am always working 😞 [0. 0. 0. 1. 0.]\n",
      "119 where is the stadium ⚾ [0. 1. 0. 0. 0.]\n",
      "120 She is the cutest person I have ever seen ❤️ [1. 0. 0. 0. 0.]\n",
      "121 vegetables are healthy 🍴 [0. 0. 0. 0. 1.]\n",
      "122 he is handsome ❤️ [1. 0. 0. 0. 0.]\n",
      "123 too bad that you were not here 😞 [0. 0. 0. 1. 0.]\n",
      "124 you are a loser 😞 [0. 0. 0. 1. 0.]\n",
      "125 I love indian food 🍴 [0. 0. 0. 0. 1.]\n",
      "126 Who is down for a restaurant 🍴 [0. 0. 0. 0. 1.]\n",
      "127 he had to make a home run ⚾ [0. 1. 0. 0. 0.]\n",
      "128 I am ordering food 🍴 [0. 0. 0. 0. 1.]\n",
      "129 What is wrong with you 😞 [0. 0. 0. 1. 0.]\n",
      "130 I love you ❤️ [1. 0. 0. 0. 0.]\n",
      "131 great job 😄 [0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"convert_to_one_hot:\")\n",
    "for index in range(len(Y_train)):\n",
    "    print(index, X_train[index], label_to_emoji(Y_train[index]), Y_oh_train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Implementing Emojifier-V1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertind an input sentence into the word 50-dimensional GloVe vector representation:\n",
    "\n",
    "We are loaded:\n",
    "\n",
    "- `word_to_index`: dictionary mapping from words to their indices in the vocabulary (400,001 words, with the valid indices ranging from 0 to 400,000)\n",
    "- `index_to_word`: dictionary mapping from indices to their corresponding words in the vocabulary\n",
    "- `word_to_vec_map`: dictionary mapping words to their GloVe vector representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('data/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text GloVo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Index: 185457 \n",
      "Word: i \n",
      "Vector: [ 1.1891e-01  1.5255e-01 -8.2073e-02 -7.4144e-01  7.5917e-01 -4.8328e-01\n",
      " -3.1009e-01  5.1476e-01 -9.8708e-01  6.1757e-04 -1.5043e-01  8.3770e-01\n",
      " -1.0797e+00 -5.1460e-01  1.3188e+00  6.2007e-01  1.3779e-01  4.7108e-01\n",
      " -7.2874e-02 -7.2675e-01 -7.4116e-01  7.5263e-01  8.8180e-01  2.9561e-01\n",
      "  1.3548e+00 -2.5701e+00 -1.3523e+00  4.5880e-01  1.0068e+00 -1.1856e+00\n",
      "  3.4737e+00  7.7898e-01 -7.2929e-01  2.5102e-01 -2.6156e-01 -3.4684e-01\n",
      "  5.5841e-01  7.5098e-01  4.9830e-01 -2.6823e-01 -2.7443e-03 -1.8298e-02\n",
      " -2.8096e-01  5.5318e-01  3.7706e-02  1.8555e-01 -1.5025e-01 -5.7512e-01\n",
      " -2.6671e-01  9.2121e-01]\n",
      "\n",
      "Index: 52943 \n",
      "Word: am \n",
      "Vector: [ 0.34664   0.39805   0.4897   -0.51421   0.54574  -1.2005    0.32107\n",
      "  0.74004  -1.4979   -0.19651  -0.12631  -0.37703  -0.62569   0.038792\n",
      "  1.0579    0.77199  -0.18589   1.3032   -0.72128   0.40231   0.066442\n",
      "  1.2315    0.93956   1.3903    1.5334   -1.473    -0.34997   0.31562\n",
      "  0.90691   0.45498   2.5481    0.1641   -0.607     0.27061  -0.79072\n",
      " -1.146     0.91795  -0.11797   0.23526  -0.12659   0.66527  -0.91816\n",
      "  0.10048   0.70457  -0.21777   0.52479  -0.54452   0.086576  0.34037\n",
      "  1.3588  ]\n",
      "\n",
      "Index: 52879 \n",
      "Word: always \n",
      "Vector: [ 1.5778e-01  2.6380e-01 -4.4502e-01 -4.6819e-01  8.8558e-01 -1.1134e-01\n",
      " -2.2886e-01  2.5545e-01 -5.3813e-01  3.3681e-01  2.2259e-02  6.7810e-01\n",
      " -4.8255e-01  2.4954e-03  5.5938e-01  4.1020e-01  6.1032e-01  1.8802e-01\n",
      "  2.2943e-01 -9.8910e-01 -7.2062e-01  5.2451e-01  3.3157e-01  4.8512e-01\n",
      "  9.6760e-01 -1.9021e+00 -9.3215e-01  4.7344e-01  8.5667e-01 -5.2803e-01\n",
      "  3.1994e+00  5.1182e-01 -8.3763e-02 -4.8335e-01 -1.2347e-01 -2.7206e-01\n",
      " -1.4103e-01  5.9470e-01 -6.1738e-01 -2.9798e-01 -1.6374e-01  8.6967e-03\n",
      " -1.2262e-01  6.6676e-01  9.7146e-02 -4.4463e-02 -2.7159e-01 -1.4953e-01\n",
      " -2.2232e-01  5.2731e-01]\n",
      "\n",
      "Index: 389883 \n",
      "Word: working \n",
      "Vector: [ 0.25792   -0.14413   -0.035634  -0.60551    0.11004   -0.058799\n",
      " -1.2209    -0.031605  -0.023699  -0.37419    0.28924    0.12331\n",
      " -0.31903    0.65017    0.28362   -0.20956    0.30423    0.75571\n",
      "  0.47964   -0.41976    0.68923    0.92026    0.070798   0.3948\n",
      "  0.24721   -1.4038    -0.14209   -0.6946    -0.035052   0.0041205\n",
      "  3.4024     0.036271  -0.58483   -0.72107    0.036996   0.33065\n",
      " -0.27332    0.51897    0.3499     0.061199  -0.36178   -0.26534\n",
      "  0.4271     0.0081181  0.19844   -0.38564   -0.35535    0.032932\n",
      " -0.50055    0.54358  ]\n"
     ]
    }
   ],
   "source": [
    "#I am always working\n",
    "print(\"\\nIndex:\", word_to_index[\"i\"], \"\\nWord:\", \"i\", \"\\nVector:\", word_to_vec_map[\"i\"])\n",
    "print(\"\\nIndex:\", word_to_index[\"am\"], \"\\nWord:\", \"am\", \"\\nVector:\", word_to_vec_map[\"am\"])\n",
    "print(\"\\nIndex:\", word_to_index[\"always\"], \"\\nWord:\", \"always\", \"\\nVector:\", word_to_vec_map[\"always\"])\n",
    "print(\"\\nIndex:\", word_to_index[\"working\"], \"\\nWord:\", \"working\", \"\\nVector:\", word_to_vec_map[\"working\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sentence_to_avg()` method convert every sentence to lower-case, then split the sentence into a list of words. For each word in the sentence, access its GloVe representation. Then, average all these values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sentence_to_avg(sentence, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    Converts a sentence (string) into a list of words (strings). Extracts the GloVe representation of each word\n",
    "    and averages its value into a single vector encoding the meaning of the sentence.\n",
    "    \n",
    "    Arguments:\n",
    "    sentence -- string, one training example from X\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    \n",
    "    Returns:\n",
    "    avg -- average vector encoding information about the sentence, numpy-array of shape (50,)\n",
    "    \"\"\"\n",
    "    \n",
    "    words = None\n",
    "    words = sentence.lower()\n",
    "    words = words.split()\n",
    "\n",
    "    avg = list()\n",
    "    for i in range(0, len(word_to_vec_map[words[0]])):\n",
    "        avg.append(0)\n",
    "    \n",
    "    for i in range(0,len(words)):\n",
    "        avg = avg + word_to_vec_map[words[i]]\n",
    "    avg = avg/len(words)\n",
    "        \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test `sentence_to_avg()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg =  [ 0.2203125   0.1675675  -0.01825675 -0.5823375   0.5751325  -0.46347975\n",
      " -0.359695    0.36966125 -0.76170225 -0.05831811  0.00868975  0.31552\n",
      " -0.6267425   0.04421435  0.804925    0.398175    0.2166125   0.6795025\n",
      " -0.021271   -0.433325   -0.176527    0.857225    0.555932    0.6414575\n",
      "  1.0257525  -1.83725    -0.6941275   0.138315    0.683832   -0.31363238\n",
      "  3.1559      0.37279275 -0.50122075 -0.1706975  -0.2846885  -0.3585625\n",
      "  0.2655025   0.43667     0.11652    -0.15790025  0.03425143 -0.29827532\n",
      "  0.031       0.48315703  0.0288805   0.07005925 -0.3304275  -0.1512855\n",
      " -0.1623025   0.837725  ]\n"
     ]
    }
   ],
   "source": [
    "avg = sentence_to_avg(\"I am always working\", word_to_vec_map)\n",
    "print(\"avg = \", avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Emojifier-V1` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "132/132 [==============================] - 3s 23ms/step - loss: 0.7403 - acc: 0.5030\n",
      "Epoch 2/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.6802 - acc: 0.6076\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.6315 - acc: 0.6682\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.5939 - acc: 0.7076\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.5645 - acc: 0.7348\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.5424 - acc: 0.7591\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 0s 697us/step - loss: 0.5249 - acc: 0.7742\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.5114 - acc: 0.7803\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.5007 - acc: 0.7924\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4914 - acc: 0.7955\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4839 - acc: 0.7970\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4775 - acc: 0.7939\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4719 - acc: 0.7939\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4671 - acc: 0.7955\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4624 - acc: 0.7970\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4583 - acc: 0.7970\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4545 - acc: 0.7985\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4513 - acc: 0.8000\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4474 - acc: 0.7985\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 0s 803us/step - loss: 0.4443 - acc: 0.8000\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4410 - acc: 0.8015\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4378 - acc: 0.8015\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4348 - acc: 0.8015\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4323 - acc: 0.8015\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4291 - acc: 0.8030\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4264 - acc: 0.8030\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4235 - acc: 0.8030\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4208 - acc: 0.8045\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 0s 652us/step - loss: 0.4179 - acc: 0.8076\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4152 - acc: 0.8061\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4126 - acc: 0.8045\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4100 - acc: 0.8106\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4075 - acc: 0.8106\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4052 - acc: 0.8121\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4028 - acc: 0.8091A: 0s - loss: 0.3972 - acc: 0.815\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4002 - acc: 0.8091\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3978 - acc: 0.8091\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.3990 - acc: 0.806 - 0s 1ms/step - loss: 0.3956 - acc: 0.8091\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3934 - acc: 0.8091\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3915 - acc: 0.8121\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3890 - acc: 0.8121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.115000). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3870 - acc: 0.8121\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3847 - acc: 0.8136\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3826 - acc: 0.8167\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3806 - acc: 0.8167\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3785 - acc: 0.8182\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3765 - acc: 0.8182\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3745 - acc: 0.8197\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3726 - acc: 0.8212\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 0s 614us/step - loss: 0.3706 - acc: 0.8227\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3687 - acc: 0.8242\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3669 - acc: 0.8242\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.3678 - acc: 0.829 - 0s 1ms/step - loss: 0.3652 - acc: 0.8288\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3636 - acc: 0.8288\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3618 - acc: 0.8318\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3601 - acc: 0.8333\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3584 - acc: 0.8333\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3568 - acc: 0.8333\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3550 - acc: 0.8364\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3536 - acc: 0.8364\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3520 - acc: 0.8379\n",
      "Epoch 62/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3501 - acc: 0.8379\n",
      "Epoch 63/100\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.3442 - acc: 0.832 - 0s 659us/step - loss: 0.3486 - acc: 0.8379\n",
      "Epoch 64/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3476 - acc: 0.8379\n",
      "Epoch 65/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3457 - acc: 0.8394\n",
      "Epoch 66/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3442 - acc: 0.8394\n",
      "Epoch 67/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3428 - acc: 0.8424\n",
      "Epoch 68/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3417 - acc: 0.8439\n",
      "Epoch 69/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3402 - acc: 0.8439\n",
      "Epoch 70/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3387 - acc: 0.8439\n",
      "Epoch 71/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3374 - acc: 0.8470\n",
      "Epoch 72/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3361 - acc: 0.8470\n",
      "Epoch 73/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3346 - acc: 0.8485\n",
      "Epoch 74/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3333 - acc: 0.8485\n",
      "Epoch 75/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3320 - acc: 0.8500\n",
      "Epoch 76/100\n",
      "132/132 [==============================] - 0s 917us/step - loss: 0.3308 - acc: 0.8515\n",
      "Epoch 77/100\n",
      "132/132 [==============================] - 0s 720us/step - loss: 0.3294 - acc: 0.8530\n",
      "Epoch 78/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3282 - acc: 0.8530\n",
      "Epoch 79/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3269 - acc: 0.8530\n",
      "Epoch 80/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3255 - acc: 0.8545\n",
      "Epoch 81/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3245 - acc: 0.8576\n",
      "Epoch 82/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3232 - acc: 0.8591\n",
      "Epoch 83/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3219 - acc: 0.8606\n",
      "Epoch 84/100\n",
      "132/132 [==============================] - 0s 962us/step - loss: 0.3208 - acc: 0.8591\n",
      "Epoch 85/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3197 - acc: 0.8621\n",
      "Epoch 86/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3187 - acc: 0.8652\n",
      "Epoch 87/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3175 - acc: 0.8652\n",
      "Epoch 88/100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.103000). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "132/132 [==============================] - 0s 682us/step - loss: 0.3163 - acc: 0.8667\n",
      "Epoch 89/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3157 - acc: 0.8636\n",
      "Epoch 90/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3141 - acc: 0.8636\n",
      "Epoch 91/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3131 - acc: 0.8667\n",
      "Epoch 92/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3126 - acc: 0.8682\n",
      "Epoch 93/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3110 - acc: 0.8727\n",
      "Epoch 94/100\n",
      "132/132 [==============================] - 0s 674us/step - loss: 0.3100 - acc: 0.8682\n",
      "Epoch 95/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3094 - acc: 0.8682\n",
      "Epoch 96/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3079 - acc: 0.8712\n",
      "Epoch 97/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3069 - acc: 0.8727\n",
      "Epoch 98/100\n",
      "110/132 [========================>.....] - ETA: 0s - loss: 0.3109 - acc: 0.869"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.132000). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3061 - acc: 0.8758\n",
      "Epoch 99/100\n",
      "132/132 [==============================] - 0s 894us/step - loss: 0.3050 - acc: 0.8773\n",
      "Epoch 100/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3041 - acc: 0.8773\n",
      "132/132 [==============================] - 1s 6ms/step\n",
      "\n",
      "acc: 87.73%\n"
     ]
    }
   ],
   "source": [
    "# Input - Layer\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=50, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "X = np.zeros((len(X_train), 50), dtype=float)\n",
    "for i in range(0, len(X_train)):\n",
    "    X[i] = sentence_to_avg(X_train[i], word_to_vec_map)\n",
    "\n",
    "model.fit(X, Y_oh_train, epochs = 100, batch_size=10)\n",
    "\n",
    "scores = model.evaluate(X, Y_oh_train)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
